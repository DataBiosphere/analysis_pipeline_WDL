# Noteable differences between CWL and WDL versions
This list is not intended as an exhaustive list of every difference. These are two different workflow languages using two different inline languages to generate configuration files after all! Instead, the purpose of this document is to keep track of changes which may have implications for maintainers of this code. This is unlikely to be of interest to the average user, except for [the one instance of known differing outputs](https://github.com/DataBiosphere/analysis_pipeline_WDL/blob/main/documentation/cwl-vs-wdl.md#different-outputs).  

# Significant Differences
These are differences that have implications for cost or outputs.  
## All Workflows
* The original CWLs allocate memory and CPUs on a workflow level, while the WDLs do it on a task level. In other words, the WDLs' runtime attributes are more granular.  
	* Reasoning: GCS has stricter requirements than AWS regarding storage. Doing it this way also allows resource-heavy tasks (such as check_gds in vcf-to-gds-wf) to only use the large number of resources they need in their respective task, instead of the whole workflow.  
* The CWL appears to contain a bug where `exclude_PCA_cor` being set to false is not respected ([#14](https://github.com/DataBiosphere/analysis_pipeline_WDL/issues/14)). The WDL avoids this. 
* Seven Bridges or its AWS backend appears to sort numbers alphabetically rather than numerically in some contexts, resulting in merged GDS files having their variants ordered differently than when the same script is run in a WDL context on a local machine or Terra (GCS backend) on the same inputs. For the testdata inputs, all variants in the output files were checked and found to be equivalent across the CWL and the WDL by splitting the variant files into subsets with correct numeric ordering. In other words, they ought to be functionally equivalent in spite of not md5ing to the same value. See [#22](https://github.com/DataBiosphere/analysis_pipeline_WDL/issues/22) for more information.   


# Less-Significant/Algorithmic Differences
These differences are likely only of interest to maintainers of this repo or those seeking to fully understand the CWL-->WDL conversion process.  

# All Workflows 
## Strictly Necessary Changes  
* **The double input workaround:** Due to [#2](https://github.com/DataBiosphere/analysis_pipeline_WDL/issues/2), some WDL tasks require up to twice as much disk space as their CWL equivalent tasks would require. This is accounted for in disk size calculations, so this should not cause users to error out, but it has minor cost implications. 
* Filenames are generated by calling the Seven Bridges API in the CWL. This isn't possible in WDL, so inputs are generated from JSONs instead.  
* The original CWL does not have an option for disk space, but the WDL does, as it is a soft requirement for running on Terra.  
* The CWL generates config files using an InlineJavascriptRequirement, which is run before the CWL equivivalent of a task's command section begins. The WDL generates them using an inline Python script during the beginning of a task's command section.  
* A few R scripts require chromosome numbers to be passed in on the command line rather than in the configuration file. In order to do this, chromosome number is written to a file (completely separate from the configuration file) in the task's inline Python section. Upon exiting the Python block, this extra file is read in BASH and then passed to the Rscript call as an argument (as opposed to being in the configuration file). Although the actual call to the R script is identical as the CWL also passes the chr number as an argument, the CWL is able to rely on its inline Javascript to do this, while the WDL must use this workaround to pass the chr number out of the Python scope.

## Miscellanous Differences
* The CWL imports other CWLs. The WDL does not import other WDLs, except in the case of the checker workflow.  
	* Reasoning: It is possible for WDLs to contain just tasks and be imported into another task, but in some contexts it can be slightly less secure.

# ld-pruning-wf.wdl
## Strictly Necessary Changes
* Similiar to vcf-to-gds' file relocalization trick in unique_variant_ids, this workflow's merge_gds task has to use the same workaround.
* WDL does not have an equivalent to ScatterMethod:DotProduct so it instead scatters using zip().
* The workaround used by vcf-to-gds' check_gds to get chromosome number (see above) is also used by check_merged_gds for the same reason.  

## Different Outputs

## Miscellanous Differences

# vcf-to-gds-wf.wdl     
## Miscellanous Differences
* The WDL will not start the check_gds task if check_gds is false. The CWL will start the check_gds task regardless and generate a config file, and the true/false only applies to calling the  script.
	* Reasoning: The way GCS billing works, this has the potential of being cheaper. Otherwise we would spend for having a powerful non-preemptible compute designed for an intense task, then only using that compute for making a text file.
* The WDL can correctly handle a mixture of file extensions, not so much by design, but due to the specifics of implementation. The CWL will handle such a mixture incorrectly in check_gds (but can correctly handle a homogenous group, such as all being bcf files).
